# GPU環境用の上書き設定ファイル
# 実行コマンド: PYTORCH_CUDA_VERSION=12.1 docker compose -f compose.yml -f compose.gpu.yml up

services:
  app:
    build:
      # build.argsをGPU用の値で上書き
      args:
        # 1. 使用したいベースイメージを選択 (この行を編集、gpu01)
        # - BASE_IMAGE=nvidia/cuda:12.1.1-cudnn8-devel-ubuntu22.04
        # PYTORCH_CUDA_VERSION=12.1 sudo docker compose -f compose.yml -f compose.gpu.yml build --progress=plain

        - BASE_IMAGE=nvidia/cuda:12.4.1-cudnn-devel-ubuntu22.04
        # PYTORCH_CUDA_VERSION=12.4 sudo docker compose -f compose.yml -f compose.gpu.yml build --progress=plain

        # 1. 使用したいベースイメージを選択 (この行を編集、gpu02)
        # - BASE_IMAGE=nvidia/cuda:12.8.0-cudnn-devel-ubuntu22.04
        # PYTORCH_CUDA_VERSION=12.8 sudo docker compose -f compose.yml -f compose.gpu.yml build --progress=plain

        # 2. GPUを有効化
        - GPU_ENABLED=true

        # 3. コマンドラインからPYTORCH_CUDA_VERSIONを受け取る (デフォルトは12.4)
        - PYTORCH_CUDA_VERSION=${PYTORCH_CUDA_VERSION:-12.4}

    # gpu01で共有メモリ不足になったら
    volumes:
      - /dev/shm:/dev/shm

    # GPUリソースを割り当てるdeployセクションを追加
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
